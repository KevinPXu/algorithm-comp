## Policy-Gradient Based Model
# PG-single (no significant learning)
This folder contains the basic model to implement a policy gradient network with REINFORCE algorithm to maximize monte-carlo returns. The average episodic returns after 5000 episodes don't show any learning patterns (run in Colab),indicating simple model not applicable to train BankHeist env. 

# PG-dual-fnn-a2c (no significant learning)
This folder contains the model with dual network, attempting to decrease variance by adding a target network and actor-critic method to improve training efficiency. 

# PG-PPO 
This folder contains the model with PPO method to optimize gradient. Since this is the only model that works on BankHeist, hyper-parameter tuning are involved in this setting. The event/runs folder stores output data after running 10M steps from file ppo_a2c_clip_only.py. 

## Training & Tuning
* Combination 1: clip_coef = 0.3, ent_coef = 0.05, l_rate = 1.0e-3, v_coe = 0.5
* Combination 2: clip_coef = 0.1, ent_coef = 0.01, l_rate = 2.5e-3,v_coe = 0.5
* Combination 3: clip_coef = 0.1, ent_coef = 0.01, l_rate = 2.5e-4,v_coe = 0.5
* Combination 4: clip_coef = 0.1, ent_coef = 0.01, l_rate = 0.5e-4,v_coe = 1.0

## Data & Outputs
* draw.py - this file plot the output of event files generated by SummaryWriter in ppo_a2c_clip_only.py. Output graphs include PPO-clip-comparison.png, PPO-clip-loss.png and PPO-clip.png.
* plot_pkl.py - this file plot the output file with .pkl.
